"""
=============================================================================
COMPARACI√ìN DE 3 METODOLOG√çAS DE PREPROCESAMIENTO DE TEXTO
=============================================================================
Script que implementa y compara EXPL√çCITAMENTE tres metodolog√≠as diferentes
de preprocesamiento de texto para predicci√≥n de calidad de vinos.

METODOLOG√çAS IMPLEMENTADAS:
1. TF-IDF B√°sico (sin limpieza NLP)
2. TF-IDF + Stopwords + Stemming
3. TF-IDF + Stopwords + Lemmatization + N-grams

Cada metodolog√≠a se aplica de forma INDEPENDIENTE y se eval√∫a con el mismo
modelo (MLP) para una comparaci√≥n justa.
=============================================================================
"""

import os
import sys
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import time
import re
import warnings
from typing import Tuple, Dict

# NLP
import nltk
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer, PorterStemmer

# ML
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neural_network import MLPRegressor
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error

# Configuraci√≥n
warnings.filterwarnings('ignore')
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

# =============================================================================
# CONFIGURACI√ìN INICIAL
# =============================================================================

# Rutas din√°micas
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.join(SCRIPT_DIR, "..", "..")
DATA_PATH = os.path.join(PROJECT_ROOT, "data", "raw", "winemag-data-130k-v2.csv")
RESULTS_DIR = os.path.join(PROJECT_ROOT, "docs", "resultados")

# Crear carpeta de resultados
os.makedirs(RESULTS_DIR, exist_ok=True)

# Verificar recursos NLTK
print("="*80)
print("COMPARACI√ìN DE 3 METODOLOG√çAS DE PREPROCESAMIENTO DE TEXTO")
print("="*80)
print("\n[1/7] Verificando recursos NLTK...")

try:
    nltk.data.find('corpora/stopwords')
    nltk.data.find('corpora/wordnet')
except LookupError:
    print("Descargando recursos NLTK...")
    nltk.download('stopwords', quiet=True)
    nltk.download('wordnet', quiet=True)
    nltk.download('omw-1.4', quiet=True)

print("‚úì Recursos NLTK listos")

# Inicializar herramientas NLP
lemmatizer = WordNetLemmatizer()
stemmer = PorterStemmer()
stop_words = set(stopwords.words('english'))


# =============================================================================
# METODOLOG√çA 1: TF-IDF B√ÅSICO (SIN LIMPIEZA NLP)
# =============================================================================
def metodologia_1_basica(texto: str) -> str:
    """
    METODOLOG√çA 1: TF-IDF B√°sico

    Descripci√≥n:
    - Solo convierte a min√∫sculas
    - NO elimina stopwords
    - NO aplica stemming ni lemmatization
    - Enfoque minimalista para baseline

    Ventaja: Preserva toda la informaci√≥n original
    Desventaja: Incluye ruido (palabras comunes sin significado)
    """
    if not isinstance(texto, str):
        return ""

    # Solo lowercase y limpieza b√°sica de s√≠mbolos
    texto = texto.lower()
    texto = re.sub(r'[^a-zA-Z\s]', '', texto)

    return texto


# =============================================================================
# METODOLOG√çA 2: TF-IDF + STOPWORDS + STEMMING
# =============================================================================
def metodologia_2_stemming(texto: str) -> str:
    """
    METODOLOG√çA 2: TF-IDF + Stopwords + Stemming

    Descripci√≥n:
    - Limpieza con regex
    - Elimina stopwords (the, is, and, etc.)
    - Aplica STEMMING (corta palabras a ra√≠z: running ‚Üí run, wines ‚Üí wine)

    Ventaja: Reduce dimensionalidad, agrupa variantes de palabras
    Desventaja: Puede perder matices sem√°nticos (stemming agresivo)

    Ejemplo:
    "This wine is complex" ‚Üí "wine complex" (stopwords eliminadas + stemming)
    """
    if not isinstance(texto, str):
        return ""

    # Limpieza
    texto = texto.lower()
    texto = re.sub(r'[^a-zA-Z\s]', '', texto)

    # Tokenizaci√≥n
    tokens = texto.split()

    # Aplicar: Stopwords + Stemming
    tokens_procesados = [
        stemmer.stem(token)  # STEMMING (PorterStemmer)
        for token in tokens
        if token not in stop_words  # Eliminar stopwords
    ]

    return " ".join(tokens_procesados)


# =============================================================================
# METODOLOG√çA 3: TF-IDF + STOPWORDS + LEMMATIZATION + N-GRAMS
# =============================================================================
def metodologia_3_lemmatization(texto: str) -> str:
    """
    METODOLOG√çA 3: TF-IDF + Stopwords + Lemmatization

    Descripci√≥n:
    - Limpieza con regex
    - Elimina stopwords
    - Aplica LEMMATIZATION (convierte a forma base preservando significado)
    - Usa n-grams (pares de palabras) en el vectorizador

    Ventaja: Preserva significado ling√º√≠stico, captura contexto (n-grams)
    Desventaja: M√°s lento computacionalmente

    Ejemplo:
    "This wine is complex" ‚Üí "wine complex" (lemmatization + preserva sem√°ntica)

    Diferencia con Stemming:
    - Stemming: "running" ‚Üí "run" (corte mec√°nico)
    - Lemmatization: "better" ‚Üí "good" (an√°lisis ling√º√≠stico)
    """
    if not isinstance(texto, str):
        return ""

    # Limpieza
    texto = texto.lower()
    texto = re.sub(r'[^a-zA-Z\s]', '', texto)

    # Tokenizaci√≥n
    tokens = texto.split()

    # Aplicar: Stopwords + Lemmatization
    tokens_procesados = [
        lemmatizer.lemmatize(token)  # LEMMATIZATION (WordNetLemmatizer)
        for token in tokens
        if token not in stop_words  # Eliminar stopwords
    ]

    return " ".join(tokens_procesados)


# =============================================================================
# FUNCI√ìN DE ENTRENAMIENTO Y EVALUACI√ìN
# =============================================================================
def entrenar_y_evaluar(
    X_train: np.ndarray,
    X_test: np.ndarray,
    y_train: np.ndarray,
    y_test: np.ndarray,
    nombre_metodologia: str
) -> Dict:
    """
    Entrena un modelo MLP y retorna m√©tricas de evaluaci√≥n
    """
    print(f"\n   ‚Üí Entrenando modelo MLP con {nombre_metodologia}...")

    start_time = time.time()

    # Modelo MLP (mismo para todas las metodolog√≠as)
    modelo = MLPRegressor(
        hidden_layer_sizes=(50, 50),
        max_iter=100,
        random_state=42,
        early_stopping=True,
        validation_fraction=0.1
    )

    modelo.fit(X_train, y_train)

    # Predicciones
    y_pred = modelo.predict(X_test)

    # M√©tricas
    mae = mean_absolute_error(y_test, y_pred)
    rmse = np.sqrt(mean_squared_error(y_test, y_pred))
    r2 = r2_score(y_test, y_pred)
    tiempo = time.time() - start_time

    print(f"   ‚úì Completado en {tiempo:.2f}s - MAE: {mae:.3f}")

    return {
        'modelo': modelo,
        'MAE': mae,
        'RMSE': rmse,
        'R¬≤': r2,
        'Tiempo (s)': tiempo,
        'y_pred': y_pred
    }


# =============================================================================
# FUNCI√ìN PRINCIPAL
# =============================================================================
def main():
    """
    Funci√≥n principal que ejecuta la comparaci√≥n de las 3 metodolog√≠as
    """

    # -------------------------------------------------------------------------
    # PASO 1: CARGAR DATOS
    # -------------------------------------------------------------------------
    print(f"\n[2/7] Cargando dataset...")

    try:
        df = pd.read_csv(DATA_PATH, usecols=['description', 'points'])
        df = df.dropna().drop_duplicates()
        print(f"‚úì Dataset cargado: {len(df)} rese√±as √∫nicas")
    except FileNotFoundError:
        print(f"ERROR: No se encontr√≥ el archivo en {DATA_PATH}")
        return

    # Limitar tama√±o para pruebas r√°pidas (opcional)
    # df = df.sample(n=10000, random_state=42)  # Descomentar para pruebas

    # -------------------------------------------------------------------------
    # PASO 2: APLICAR LAS 3 METODOLOG√çAS DE PREPROCESAMIENTO
    # -------------------------------------------------------------------------
    print(f"\n[3/7] Aplicando las 3 metodolog√≠as de preprocesamiento...")

    print("\n   METODOLOG√çA 1: TF-IDF B√°sico (sin limpieza NLP)")
    t0 = time.time()
    df['metodo_1_basico'] = df['description'].apply(metodologia_1_basica)
    print(f"   ‚úì Completado en {time.time()-t0:.2f}s")

    print("\n   METODOLOG√çA 2: TF-IDF + Stopwords + Stemming")
    t0 = time.time()
    df['metodo_2_stemming'] = df['description'].apply(metodologia_2_stemming)
    print(f"   ‚úì Completado en {time.time()-t0:.2f}s")

    print("\n   METODOLOG√çA 3: TF-IDF + Stopwords + Lemmatization")
    t0 = time.time()
    df['metodo_3_lemmatization'] = df['description'].apply(metodologia_3_lemmatization)
    print(f"   ‚úì Completado en {time.time()-t0:.2f}s")

    # Mostrar ejemplos
    print("\n" + "="*80)
    print("EJEMPLO DE PREPROCESAMIENTO CON LAS 3 METODOLOG√çAS:")
    print("="*80)
    ejemplo_idx = 42
    print(f"\nRESE√ëA ORIGINAL:\n'{df['description'].iloc[ejemplo_idx]}'")
    print(f"\nMETODOLOG√çA 1 (B√°sico):\n'{df['metodo_1_basico'].iloc[ejemplo_idx]}'")
    print(f"\nMETODOLOG√çA 2 (Stemming):\n'{df['metodo_2_stemming'].iloc[ejemplo_idx]}'")
    print(f"\nMETODOLOG√çA 3 (Lemmatization):\n'{df['metodo_3_lemmatization'].iloc[ejemplo_idx]}'")
    print("="*80)

    # -------------------------------------------------------------------------
    # PASO 3: VECTORIZACI√ìN Y DIVISI√ìN DE DATOS
    # -------------------------------------------------------------------------
    print(f"\n[4/7] Vectorizando con TF-IDF...")

    y = df['points'].values
    resultados = {}

    # METODOLOG√çA 1: TF-IDF b√°sico (sin n-grams)
    print("\n   ‚Üí Vectorizando Metodolog√≠a 1...")
    vectorizer_1 = TfidfVectorizer(max_features=3000, ngram_range=(1, 1))
    X_1 = vectorizer_1.fit_transform(df['metodo_1_basico']).toarray()
    X_train_1, X_test_1, y_train, y_test = train_test_split(
        X_1, y, test_size=0.2, random_state=42
    )
    print(f"   ‚úì Shape: {X_1.shape}")

    # METODOLOG√çA 2: TF-IDF (sin n-grams para stemming)
    print("\n   ‚Üí Vectorizando Metodolog√≠a 2...")
    vectorizer_2 = TfidfVectorizer(max_features=3000, ngram_range=(1, 1))
    X_2 = vectorizer_2.fit_transform(df['metodo_2_stemming']).toarray()
    X_train_2, X_test_2, _, _ = train_test_split(
        X_2, y, test_size=0.2, random_state=42
    )
    print(f"   ‚úì Shape: {X_2.shape}")

    # METODOLOG√çA 3: TF-IDF + N-grams (1,2) - captura contexto
    print("\n   ‚Üí Vectorizando Metodolog√≠a 3 (con bigramas)...")
    vectorizer_3 = TfidfVectorizer(max_features=3000, ngram_range=(1, 2))
    X_3 = vectorizer_3.fit_transform(df['metodo_3_lemmatization']).toarray()
    X_train_3, X_test_3, _, _ = train_test_split(
        X_3, y, test_size=0.2, random_state=42
    )
    print(f"   ‚úì Shape: {X_3.shape}")

    # -------------------------------------------------------------------------
    # PASO 4: ENTRENAR MODELOS CON CADA METODOLOG√çA
    # -------------------------------------------------------------------------
    print(f"\n[5/7] Entrenando modelos MLP con cada metodolog√≠a...")

    resultados['Metodolog√≠a 1: TF-IDF B√°sico'] = entrenar_y_evaluar(
        X_train_1, X_test_1, y_train, y_test, "Metodolog√≠a 1"
    )

    resultados['Metodolog√≠a 2: Stemming'] = entrenar_y_evaluar(
        X_train_2, X_test_2, y_train, y_test, "Metodolog√≠a 2"
    )

    resultados['Metodolog√≠a 3: Lemmatization + N-grams'] = entrenar_y_evaluar(
        X_train_3, X_test_3, y_train, y_test, "Metodolog√≠a 3"
    )

    # -------------------------------------------------------------------------
    # PASO 5: COMPARACI√ìN DE RESULTADOS
    # -------------------------------------------------------------------------
    print(f"\n[6/7] Comparando resultados...")

    # Crear DataFrame de resultados
    df_resultados = pd.DataFrame({
        'Metodolog√≠a': list(resultados.keys()),
        'MAE': [r['MAE'] for r in resultados.values()],
        'RMSE': [r['RMSE'] for r in resultados.values()],
        'R¬≤': [r['R¬≤'] for r in resultados.values()],
        'Tiempo (s)': [r['Tiempo (s)'] for r in resultados.values()]
    })

    # Ordenar por MAE (menor es mejor)
    df_resultados = df_resultados.sort_values('MAE')

    print("\n" + "="*80)
    print("RESULTADOS DE LA COMPARACI√ìN")
    print("="*80)
    print(df_resultados.to_string(index=False))
    print("="*80)

    # Identificar mejor metodolog√≠a
    mejor_metodo = df_resultados.iloc[0]['Metodolog√≠a']
    mejor_mae = df_resultados.iloc[0]['MAE']

    print(f"\nüèÜ MEJOR METODOLOG√çA: {mejor_metodo}")
    print(f"   MAE: {mejor_mae:.3f} puntos")
    print(f"   (Menor error promedio en la predicci√≥n)")

    # -------------------------------------------------------------------------
    # PASO 6: VISUALIZACIONES
    # -------------------------------------------------------------------------
    print(f"\n[7/7] Generando visualizaciones comparativas...")

    # Gr√°fico 1: Comparaci√≥n de MAE
    fig, axes = plt.subplots(1, 2, figsize=(14, 5))

    # MAE
    ax1 = axes[0]
    bars = ax1.bar(
        range(len(df_resultados)),
        df_resultados['MAE'],
        color=['#2ecc71' if i == 0 else '#3498db' for i in range(len(df_resultados))]
    )
    ax1.set_xticks(range(len(df_resultados)))
    ax1.set_xticklabels(df_resultados['Metodolog√≠a'], rotation=15, ha='right')
    ax1.set_ylabel('MAE (Mean Absolute Error)')
    ax1.set_title('Comparaci√≥n de Error por Metodolog√≠a\n(Menor es Mejor)', fontweight='bold')
    ax1.grid(axis='y', alpha=0.3)

    # Anotar valores
    for i, bar in enumerate(bars):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}',
                ha='center', va='bottom', fontweight='bold')

    # R¬≤
    ax2 = axes[1]
    bars2 = ax2.bar(
        range(len(df_resultados)),
        df_resultados['R¬≤'],
        color=['#2ecc71' if i == 0 else '#e74c3c' for i in range(len(df_resultados))]
    )
    ax2.set_xticks(range(len(df_resultados)))
    ax2.set_xticklabels(df_resultados['Metodolog√≠a'], rotation=15, ha='right')
    ax2.set_ylabel('R¬≤ Score')
    ax2.set_title('Coeficiente de Determinaci√≥n por Metodolog√≠a\n(Mayor es Mejor)', fontweight='bold')
    ax2.grid(axis='y', alpha=0.3)
    ax2.set_ylim([0, 1])

    # Anotar valores
    for i, bar in enumerate(bars2):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{height:.3f}',
                ha='center', va='bottom', fontweight='bold')

    plt.tight_layout()

    # Guardar gr√°fico
    output_path = os.path.join(RESULTS_DIR, 'comparacion_metodologias.png')
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\n‚úì Gr√°fico guardado: {output_path}")

    plt.show()

    # -------------------------------------------------------------------------
    # RESUMEN FINAL
    # -------------------------------------------------------------------------
    print("\n" + "="*80)
    print("RESUMEN DE METODOLOG√çAS")
    print("="*80)
    print("""
METODOLOG√çA 1: TF-IDF B√°sico
‚îú‚îÄ Preprocesamiento: M√≠nimo (solo lowercase)
‚îú‚îÄ Ventaja: R√°pido, simple, preserva informaci√≥n
‚îî‚îÄ Desventaja: Incluye ruido (stopwords)

METODOLOG√çA 2: TF-IDF + Stopwords + Stemming
‚îú‚îÄ Preprocesamiento: Intermedio (limpieza + stemming)
‚îú‚îÄ Ventaja: Reduce dimensionalidad, agrupa variantes
‚îî‚îÄ Desventaja: Stemming agresivo puede perder matices

METODOLOG√çA 3: TF-IDF + Stopwords + Lemmatization + N-grams
‚îú‚îÄ Preprocesamiento: Avanzado (lemmatization + bigramas)
‚îú‚îÄ Ventaja: Preserva sem√°ntica, captura contexto
‚îî‚îÄ Desventaja: M√°s lento computacionalmente
    """)
    print("="*80)

    print(f"\n‚úì PROCESO COMPLETADO EXITOSAMENTE")
    print(f"‚úì Resultados guardados en: {RESULTS_DIR}")


# =============================================================================
# PUNTO DE ENTRADA
# =============================================================================
if __name__ == "__main__":
    main()
